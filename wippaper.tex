% \documentclass[12pt,twocolumn]{article}
% Copernicus stuff
\documentclass[gmd,manuscript]{copernicus}
%\documentclass[gmd,manuscript]{../171128_Copernicus_LaTeX_Package/copernicus} %durack

% page/line labeling and referencing
% from http://goo.gl/HvS9BK
% \newcommand{\pllabel}[1]{\label{p-#1}\linelabel{l-#1}}
% \newcommand{\plref}[1]{page~\pageref{p-#1}, line~\lineref{l-#1}}
% answer environment for reviewer responses
% \newenvironment{answer}{\color{blue}}{}

\hypersetup{colorlinks=true,urlcolor=blue,citecolor=red}
% \newcommand{\degree}{\ensuremath{^\circ}}
% \newcommand{\order}{\ensuremath{\mathcal{O}}}
\newcommand{\bibref}[1] { \cite{ref:#1}}
\newcommand{\pipref}[1] {\citep{ref:#1}}
% \newcommand{\ceqref}[1] {\mbox{CodeBlock \ref{code:#1}}}
% \newcommand{\charef}[1] {\mbox{Chapter \ref{cha:#1}}}
% \newcommand{\eqnref}[1] {\mbox{Eq.     \ref{eq:#1}}}
\newcommand{\figref}[1] {\mbox{Figure   \ref{fig:#1}}}
\newcommand{\secref}[1] {\mbox{Section  \ref{sec:#1}}}
\newcommand{\appref}[1] {\mbox{Appendix \ref{sec:#1}}}
% \newcommand{\tabref}[1] {\mbox{Table   \ref{tab:#1}}}

\newcommand{\editorial}[1]{\protect{\color{red}#1}}

\runningtitle{WIP Paper Draft \today}
\runningauthor{Balaji et al.}

\begin{document}

\title{Requirements for a global data infrastructure in support of CMIP6}
% \pllabel{SC1-1}

\Author[1,2]{V.}{Balaji}
\Author[3]{Karl E.}{Taylor}
\Author[4]{Martin}{Juckes}
\Author[5]{Michael}{Lautenschlager}
\Author[6,2]{Chris}{Blanton}
\Author[7]{Luca}{Cinquini}
\Author[8]{S\'ebastien}{Denvil}
\Author[3]{Paul J.}{Durack}
\Author[9]{Mark}{Elkington}
\Author[8]{Francesca}{Guglielmo}
\Author[8,10]{Eric}{Guilyardi}
\Author[10]{David}{Hassell}
\Author[11]{Slava}{Kharin}
\Author[5]{Stefan}{Kindermann}
\Author[10,4]{Bryan N.}{Lawrence}
\Author[1,2]{Sergey}{Nikonov}
\Author[6,2]{Aparna}{Radhakrishnan}
\Author[5]{Martina}{Stockhause}
\Author[3]{Dean}{Williams}


\affil[1]{Princeton University, Cooperative Institute of Climate
  Science, Princeton NJ, USA}
\affil[2]{NOAA/Geophysical Fluid Dynamics Laboratory, Princeton NJ,
  USA}
\affil[3]{PCMDI, Lawrence Livermore National Laboratory, Livermore, CA, USA}
\affil[4]{Science and Technology Facilities Council, Abingdon, UK}
\affil[5]{Deutsches KlimaRechenZentrum GmbH, Hamburg, Germany}
\affil[6]{Engility Inc., NJ, USA}
\affil[7]{NASA/JPL}
\affil[8]{Institut Pierre-Simon Laplace, CNRS/UPMC, Paris, France}
\affil[9]{UKMO}
\affil[10]{National Center for Atmospheric Science and University of
  Reading, UK}
\affil[11]{CCCma}
% \affil[10]{NCAR}

\correspondence{V. Balaji (\texttt{balaji@princeton.edu})}

\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

%% These dates will be inserted by Copernicus Publications during the typesetting process.


\firstpage{1}

\maketitle

% \pagebreak
\abstract{The World Climate Research Programme (WCRP)'s Working Group
  on Climate Modeling (WGCM) Infrastructure Panel (WIP) was formed in
  2014 in response to the explosive growth in size and complexity of
  Coupled Model Intercomparison Projects (CMIPs) between CMIP3
  (2005-06) and CMIP5 (2011-12). This article presents the WIP
  recommendations for the global data infrastructure needed to support
  CMIP design, future growth and evolution. Developed in close
  coordination with those who build and run the existing
  infrastructure (the Earth System Grid Federation), the
  recommendations are based on several principles beginning with the
  need to separate requirements, implementation, and operations. Other
  important principles include the consideration of data as a
  commodity in an ecosystem of users, the importance of provenance,
  the need for automation, and the obligation to measure costs and
  benefits.
  
  This paper concentrates on requirements, recognising the diversity
  of communities involved (modelers, analysts, software developers, 
  and downstream users). Such requirements include the need for 
  scientific reproducibility and accountability alongside the need 
  to record and track data usage for the purpose of assigning
  credit. One key element is to generate a dataset-centric rather 
  than system-centric focus, with an aim to making the 
  infrastructure less prone to systemic failure.

  With these overarching principles and requirements, the WIP has
  produced a set of position papers, which are summarized here. They
  provide specifications for managing and delivering model output,
  including strategies for replication and versioning, licensing, data
  quality assurance, citation, long-term archival, and dataset
  tracking. They also describe a new and more formal approach for
  specifying what data, and associated metadata, should be saved,
  which enables future data volumes to be estimated.
 
  The paper concludes with a future-facing consideration of the global
  data infrastructure evolution that follows from the blurring of
  boundaries between climate and weather, and the changing nature of
  published scientific results in the digital age. }
% \pagebreak

\introduction
\label{sec:intro}

CMIP6 \pipref{eyringetal2016a}, the latest Coupled Model
Intercomparison Project (CMIP), can trace its genealogy back to the
Charney Report \pipref{charneyetal1979}. This seminal report on the
links between CO$_2$ and climate was an authoritative summary of the
state of the science at the time, and produced findings that have
stood the test of time \pipref{bonyetal2013}. It is often noted that
the range and uncertainty bounds on equilibrium climate sensitivity
generated in this report have not fundamentally changed, despite the
enormous increase in resources devoted to analysing the problem in
decades since.

Beyond its prescient findings on climate sensitivity, the Charney
Report also gave rise to a methodology for the treatment of
uncertainties and gaps in understanding, which has been equally
influential, and is in fact the basis of CMIP itself. The Report can
be seen as one of the first uses of the \emph{multi-model ensemble}.
At the time, there were two models capable of representing the
equilibrium response of the climate system to a change in CO$_2$
forcing, one from Syukuro Manabe's group at NOAA's Geophysical Fluid
Dynamics Laboratory, and the other from James Hansen's group at NASA's
Goddard Institute for Space Studies. Then as now, these groups
marshaled vast state-of-the-art computing and data resources to run
very challenging simulations of the Earth system. The Report's results
were based on an ensemble of 3 runs from Manabe, labeled M1-M3, and
two from Hansen, labeled H1-H2.

By the time of the IPCC First Assessment Report (FAR) in 1990, the
process had been formalized. At this stage, there were 5 models
participating in the exercise, and some of what has now been
formalized as the ``Diagnosis, Evaluation, and Characterization of
Klima'' (DECK) experiments\footnote{``Klima'' is German for
  ``climate''.} had been standardized (a pre-industrial control, 1\%
per year CO$_2$ increase to doubling, etc). The ``scenarios'' had
emerged as well, for a total of 5 different experimental protocols.
Fast-forwarding to today, CMIP6 expects more than 75 models from
around 35 modeling centers \citep[in 14 countries, a stark contrast
to the US monopoly in][]{ref:charneyetal1979} to participate in the
DECK and historical experiments \citep[Table~2
of][]{ref:eyringetal2016a}, and some subset of these to participate in
one or more the 21 MIPs endorsed by the CMIP Panel \citep[Table~3
of][]{ref:eyringetal2016a}. The MIPs call for over 200 experiments, a
considerable expansion over CMIP5.

Alongside the experiments themselves is the data request which
defines, for each CMIP experiment, what output each model should
provide for analysis. The complexity of this data request has also
grown tremendously over the CMIP era. A typical dataset from the FAR
archive (\href{https://goo.gl/M1WSJy}{from the GFDL R15 model}) lists
climatologies and time series of two variables, and the dataset size
is about 200~MB. The CMIP6 Data Request \cite{ref:juckesetal2015}
lists literally thousands of variables from the hundreds of
experiments mentioned above. This growth in complexity is testament to
the modern understanding of many physical, chemical and biological
processes which were simply absent from the Charney Report era models.

The simulation output is now a primary scientific resource for
researchers the world over, rivaling the volume of observed weather
and climate data from the global array of sensors and satellites
\pipref{overpecketal2011}. Climate science, and observed and simulated
climate data in particular, have now become primary elements in the
``vast machine'' \pipref{edwards2010} serving the global climate and
weather enterprise.
% It could be worthwhile to quantify (in $USD) the impact, as forecasting
% in particular has yielded considerable social and economic gains

Managing and sharing this huge amount of data is an enterprise in its
own right -- and the solution established for CMIP5 was the global
``Earth System Grid Federation'' (ESGF, \pipref{williamsetal2015}).
ESGF was identified by the WCRP Joint Scientific Committee in 2013 as
the recommended infrastructure for data archiving and dissemination
for the Programme. The larger gateways currently participating in the
ESGF are shown in in \figref{esgf}, which also lists (some of) the
many projects these nodes support. With multiple agencies and
institutions, and many uncoordinated and possibly conflicting
requirements, the ESGF itself is a complex and delicate component to
manage.

\begin{figure*}
  \begin{center}
    \includegraphics[width=175mm]{images/esgf-map-2017.png}
  \end{center}
  \caption{Sites participating in the Earth System Grid Federation in
    2017. Figure courtesy Dean Williams, adapted from the ESGF
    Brochure. }
  \label{fig:esgf}
\end{figure*}

The sheer size and complexity of this infrastructure emerged as a
matter of great concern at the end of CMIP5, when the growth in data
volume relative to CMIP3 (from 40~TB to 2~PB, a 50-fold increase in 6
years) suggested the community was on an unsustainable path. These
concerns led to the 2014 recommendation of the WGCM to form an
\emph{infrastructure panel} (based upon \href{https://goo.gl/FHqbNN},
a proposal at the 2013 annual meeting). The WGCM Infrastructure Panel
(WIP) was tasked with examining the global computational and data
infrastructure underpinning CMIP, and improving communication between
the teams overseeing the scientific and experimental design of these
globally coordinated experiments, and the teams providing resources
and designing that infrastructure. The communication was intended to
be two-way: providing input both to the provisioning of infrastructure
appropriate to the experimental design, and informing the scientific
design of the technical (and financial) limits of that infrastructure.

This paper is a summary of the requirements identified by the WIP in
the first three years of activity since its formation in 2014,
alongside the recommendations which have arisen. In
\secref{principles}, the principles and scientific rationale
underlying the requirements for global data infrastructure are
articulated. In \secref{dreq} the CMIP6 Data Request is covered:
standards and conventions, requirements for modeling centers to
process a complex data request, and projections of data volume. 
In \secref{licensing}, recent
evolution in how data are archived is reviewed alongside a licensing
strategy consistent with current practice and scientific principle. In
\secref{cite} issues surrounding data as a citable resource are
discussed, including the technical infrastructure for the creation of
citable data, and the documentation and other standards required to
make data a first-class scientific entity. In \secref{replica} the
implications of data replicas and in \secref{version} issues
surrounding data versioning, retraction, and errata are addressed.
\secref{summary} provides an outlook for the future of global data
infrastructure, looking beyond CMIP6 towards a unified view of
the ``vast machine'' for weather and climate computation and data.

\section{Principles underlying the infrastructure requirements}
\label{sec:principles}

In the pioneering days of CMIP, the community of participants was
small and well-knit, and all the issues involved in generating
datasets for common analysis from different modeling groups could be
settled by mutual agreement (Ron Stouffer, personal communication).
Analysis was performed by the same community that performed the
simulations. The Program for Climate Model Diagnostics and
Intercomparison (PCMDI), established in 1989, had championed the idea
of more systematic analysis of models, and in close cooperation with
the climate modeling centers, PCMDI assumed responsibility for
much of the day-to-day coordination of CMIP. Until CMIP3, the hosting
of datasets from different modeling groups could be managed at a
single archival site; PCMDI alone hosted the entire 40~TB archive.

From its earliest phases, CMIP grew in importance, and its results
provided a major pillar supporting the periodic Intergovernmental
Panel on Climate Change (IPCC) assessment activity. However, the
explosive growth in the scope of CMIP, especially between CMIP3 and
CMIP5, represented a tipping point in the supporting infrastructure. 
It became evident that fundamental changes would be needed to address 
the evolving scientific and operational requirements, which are summarized
here:

\begin{enumerate}
\item With greater complexity and a globally distributed data
  resource, it has become clear that in the design of globally
  coordinated scientific experiments, the global computational and
  data infrastructure needs to be formally examined as an integrated
  element.

  \begin{itemize}
  \item The WIP was formed in response to this observation, with
    membership drawn from experts in various aspects of the
    infrastructure. Representatives of modeling centers,
    infrastructure developers, and stakeholders in the scientific
    design of CMIP and its output comprise the panel membership.
  \item One of the WIP's first acts was to consider three phases in
    the process of infrastructure development: \emph{requirements},
    \emph{implementation}, and \emph{operations}, all informed by the
    builders of workflows at the modeling centers.
    
    \begin{itemize}
    \item The WIP, in consort with the CMIP Panel, takes
      responsibility to articulate requirements for the
      infrastructure.
    \item The implementation is in the hands of the infrastructure
      developers, principally ESGF for the federated archive
      \pipref{williamsetal2015}, but also related projects like Earth
      System Documentation
      \citep[\href{https://goo.gl/WNwKD9}{ES-DOC},][]{ref:guilyardietal2013}.
    \item In 2016 at the WIP's request, the CMIP6 Data Node Operations
      Team (CDNOT) was formed. It is charged with ensuring that all
      the infrastructure elements needed by CMIP6 are properly
      deployed and actually working as intended at the sites hosting
      CMIP6 data. It is also responsible for the operational aspects
      of the federation itself, including specifying what versions of
      the toolchain are run at every site at any given time, and
      organizing coordinated version upgrades across the federation.
   \end{itemize} Although there is now a clear separation of concerns
   into requirements, implementation, and operations, close links are
   maintained by cross-membership between the key bodies, including
   the WIP itself, the CMIP Panel, the ESGF Executive Committee, and
   the CDNOT.
 \end{itemize}
\item\label{broad} With the basic fact of anthropogenic climate change
  now well established \citep[see, e.g.,][]{ref:stockeretal2013}
  % A ref would be useful here - the AR5 technical summary for policy makers?
  the scientific communities with an interest in CMIP is expanding.
  For example, a substantial body of work has begun to emerge to
  examine climate impacts.
  \begin{itemize}
  \item In addition to the specialists in Earth system science -- who
    also design and run the experiments and produce the model output
    -- those relying on CMIP output now include those developing and
    providing climate services, as well as \emph{consumers} from
    allied fields studying the impacts of climate change on health,
    agriculture, natural resources, human migration, and similar
    issues \pipref{mossetal2010}. This confronts us with a
    \emph{scientific scalability} issue (the data during its lifetime
    will be consumed by a community much larger, both in sheer
    numbers, and also in breadth of interest and perspective than the
    Earth system modeling community itself), which needs to be
    addressed.
  \item Accordingly, the WIP has promulgated the requirement that 
    infrastructure should ensure maximum transparency and usability
    for user (consumer) communities at some distance from the modeling
    (producer) communities.
  \end{itemize}
\item\label{repro} While CMIP and the IPCC are formally independent,
  the CMIP archive is increasingly a reference in formulating
  climate policy. Hence the \emph{scientific reproducibility}
  \pipref{collinstabak2014} and the underlying \emph{durability} and
  \emph{provenance} of data have now become matters of central
  importance: being able to trace, long after the fact, back from
  model output to the configuration of models and analysis procedures
  and choices made along the way.
  \begin{itemize}
  \item This led the IPCC to require data distribution centers (DDCs)
    to attempt to guarantee the archival and dissemination of this
    data in perpetuity, and
  \item the WIP to promote the importance in the CMIP context of
    achieving reproducibility. Given the use of multi-model ensembles
    for both consensus estimates and uncertainty bounds on climate
    projections, it is important to document -- as precisely as
    possible, given the independent genealogy and structure of many
    models -- the details and differences among model configurations
    and analysis methods, to deliver both the requisite provenance and
    the routes to reproduction.
  \end{itemize}
\item\label{analysis} With the expectation that CMIP DECK experiment
  results should be routinely contributed to CMIP, opportunities now
  exist for engaging in a more systematic and routine evaluation of
  Earth System Models (ESMs). This has led to community efforts to
  develop standard metrics of model ``quality''
  \citep{ref:eyringetal2016,ref:gleckleretal2016}.
  \begin{itemize}
  \item Typical multi-model analysis has hitherto taken the
    multi-model average, assigning equal weight to each model, as the
    most likely estimate of climate response. This ``model democracy''
    \pipref{knutti2010} has been called into question and there is now
    a considerable literature exploring the potential of weighting
    models by quality \pipref{knuttietal2017}. The development of
    standard metrics would aid this kind of research.
  \item To that end, there is now a requirement to enable through the
    ESGF a framework for accommodating quasi-operational evaluation
    tools that could routinely execute a series of standardized
    evaluation tasks. This would provide data consumers with an
    increasingly (over time) systematic characterization of models.
    The WIP recognizes it may be some time before a fully operational
    system of this kind can be implemented, but planning must start now.
  \end{itemize}
\item As the experimental design of CMIP has grown in complexity,
  costs both in time and money have become a matter of great concern,
  particularly for those designing, carrying out, and storing
  simulations. In order to justify commitment of resources to CMIP,
  mechanisms to identify costs and benefits in developing new models,
  performing CMIP simulations, and disseminating the model output need
  to be developed.

  \begin{itemize}
  \item To quantify the scientific impact of CMIP, measures are needed
    to \emph{track} the use of model output and its value to consumers.
  \item In addition to usage quantification, credit and tracing data
    usage in literature via citation of data is important. Current
    practice is at best citing large data collections provided by a
    CMIP participant, or all of CMIP. Accordingly, the WIP has defined
    and is encouraging use of a mechanism to identify and \emph{cite}
    data provided by each modeling center.
  \item Alongside the intellectual contribution to model development,
    which can be recognized by citation, there is a material cost to
    centers in computing which is both burdensome and poorly
    understood by those requesting, designing and using CMIP
    experiments.  To begin documentation of these costs for CMIP6,
    the ``Computational Performance'' MIP
    project (CPMIP) \pipref{balajietal2017} has been established.
  \end{itemize}
\item\label{cmplx} Experimental specifications have become ever more
  complex, making it difficult to verify that experiment
  configurations conform to those specifications.
 \begin{itemize} 
 \item Several modeling centers have encountered this problem in
   preparing for CMIP6, noting, for example, the challenging
   intricacies in dealing with input forcing data
   \citep[see][]{ref:duracketal2017}, output variable lists
   \pipref{juckesetal2015}, and crossover requirements between the
   endorsed MIPs and the DECK \pipref{eyringetal2016a} . Moreover,
   these protocols inevitably evolve over time, as errors are
   discovered or enhancements proposed, and centers needed to be 
   adaptable in their workflows accordingly.
 \item The WIP therefore recognized a requirement to encode the
   protocols to be directly ingested by workflows, in other words,
   \emph{machine-readable experiment design}. The requirement spans
   all of the \emph{controlled vocabularies} (CVs: for instance the
   names assigned to models, experiments, and output variables) used
   in the CMIP protocols as well as the CMIP6 Data Request
   \pipref{juckesetal2015}, which must be stored in
   version-controlled, machine-readable formats. Precisely documenting
   the \emph{conformance} of experiments to the protocols
   \pipref{lawrenceetal2012} is an additional requirement.
  \end{itemize}
\item\label{snap} The transition from a unitary archive at PCMDI in
  CMIP3 to a globally federated archive in CMIP5 led to many changes
  in the way users interact with the archive, which impacts management
  of information about users and complicates communications with them.
  \begin{itemize}
  \item In particular, a growing number of data users no longer
    register or interact directly with the ESGF. Rather they rely on
    secondary repositories, often ``snapshots'' of the state of some
    portion of the ESGF archive created by others at a particular time
    (see for instance the \href{https://goo.gl/34AtW6}{IPCC CMIP5 Data
      Factsheet} for a discussion of the snapshots and their
    coverage). This meant that reliance on the ESGF's inventory of
    registered users for any aspect of the infrastructure -- such as
    tracking usage, compliance with licensing requirements, or
    informing users about errata or retractions -- could at best
    ensure partial coverage of the user base.
  \item The WIP therefore committed to a more distributed design for
    several features outlined below, which devolve many of these
    features to the datasets themselves rather than the archives. One
    may think of this as a \emph{dataset-centric rather than
      system-centric} design (in software terms, a \emph{pull} rather
    than \emph{push} design): information is made available upon
    request at the user/dataset level, relieving the ESGF
    implementation of an impossible burden.
  \end{itemize}
\end{enumerate}

Based upon these considerations, the WIP produced a set of position
papers (see \appref{wip}) encapsulating specifications and
recommendations for CMIP6 and beyond. These papers, summarized below,
are available from the
\href{https://www.earthsystemcog.org/projects/wip/}{WIP website}. As
the WIP continues to develop additional recommendations, they too will
be made available. All WIP papers distributed in this way are thought
be stable, but should revision be necessary, a modified document will
be released with a new version number.

\section{A structured approach to data production}
\label{sec:dreq}

The CMIP6 data framework has evolved considerably from CMIP5, and
follows the principles of scientific reproducibility (Item~\ref{repro}
in \secref{principles}), and the recognition that the complexity of
the experimental design (Item~\ref{cmplx}) required far greater
degrees of automation and embedding in workflows. This requires that 
all elements in the specification be recorded in structured text
formats (XML and JSON, for example), and subject to rigorous version
control. \emph{Machine-readable} specification of as many aspects of
the model output configuration as possible is a WIP design goal.

The data request spans several elements discussed in sub-sections
below.

\subsection{CMIP6 Data Request}
\label{sec:data-request}

The data request \pipref{juckesetal2015} is now available
through the \href{https://goo.gl/iNBQ9m}{DREQ} tool, the associated
\texttt{dreqPy} Python library, and underlying
% Martin refs to this as "dreq", with the software "dreqPy"
database. The DREQ combines definitions of variables and their output
format with specifications of the objectives they support and the
experiments that they are required for. The entire request is encoded
in an XML database with rigorous type constraints. Important elements
of the request, such as units, cell methods (expressing the sub-grid
processing implicit in the variable definition), and time slices for
required output, are defined as controlled vocabularies within the
request to ensure consistency of usage. The request is designed to
enable flexibility, allowing modeling centers to make informed
decisions about the variables they should submit to the CMIP6 archive
from each experiment.

The data request spans several elements.

\begin{enumerate}
\item specification of the parameter to be calculated in terms of a CF
  standard name and units,
\item an output frequency,
\item a structural specification which includes specification of
  dimensions and of sub-grid processing.
\end{enumerate}

In order to facilitate the cross linking between the 2100 variables
from 248 experiments, the request database allows MIPs to aggregate
variables and experiments into groups. The link between variables and
experiments is then made through the following chain:

\begin{enumerate}
\item A \emph{variable group}, aggregating variables with priorities
  specific to the MIP defining the group;
\item A \emph{request link} associating a variable group with an
  objective and a set of request items;
\item \emph{Request} items associating a particular time slice with a
  request link and a set of experiments.
\end{enumerate}

This formulation takes into account the complexities that arise  
when a particular MIP requests that variables needed for
their own experiments should also
be saved from a DECK experiment or from  an experiment proposed 
by a different MIP.

The data request supports a broad range of users who are 
provided with a range of different access points.

\begin{enumerate}
\item The XML database provides the reference document;
\item Web pages provide a direct representation of the database
  content;
\item Excel workbooks provide selected overviews for specific MIPs and
  experiments;
\item A python library provides an interface to the database with some
  built-in support functions;
\item A command line tool based on the python library allows quick
  access to simple queries.
\end{enumerate}

The data request's machine-readable database, which is accessible
through a simple python API, has been an extraordinary resource for
the modeling centers. They can, for example, directly integrate the
request specifications with their workflows to ensure that the correct
set of variables are saved for each experiment they plan to run. In
addition, it has given them a new-found ability to estimate the data
volume associated with meeting a MIP's requirements, a feature
exploited below in \secref{dvol}.

\subsection{Model inputs}
\label{sec:data-inputs}

Datasets used by the model for configuration of model inputs
\citep[\texttt{input4MIPs}, see][]{ref:duracketal2017} as well as
observations for comparison with models \citep[\texttt{obs4MIPs},
see][]{ref:teixeiraetal2014} are both now organized in the same way, 
and share many of the naming and metadata conventions as the
CMIP model output itself. The datasets follow versioning
methodologies recommended by the WIP.

\subsection{Data Reference Syntax}
\label{sec:data-drs}

The organization of the model output follows the
\href{http://goo.gl/v1drZl}{Data Reference Syntax (DRS)} first used in
CMIP5, and now in somewhat modified form in CMIP6. The DRS depends on
pre-defined \emph{controlled vocabularies} (CVs) for various terms
including: the names of institutions, models, experiments, time
frequencies, etc. The CVs are now recorded as a version-controlled set
of structured text documents, and the WIP has taken steps to ensure
that there is a \href{https://goo.gl/HGafnJ}{single authoritative
  source for any CV}, on which all elements in the toolchain will
rely. The DRS elements that rely on these controlled vocabularies
appear as netCDF attributes and are used in constructing file names,
directory names, and unique identifiers of datasets that are essential
throughout the CMIP6 infrastructure. These aspects are covered in
detail in the \href{https://goo.gl/mSe4rf}{CMIP6 Global Attributes,
  DRS, Filenames, Directory Structure, and CVs} position paper. A new
element in the DRS indicates whether data has been stored on a native
grid or has been regridded.
%  the rest of this subsectio seems not to fit in the section. can it be moved or removed?
% how does it related to data reference syntax?
(see discussion below in \secref{dvol} on the potentially critical
role of regridded output). Regridding, in particular, remains a
contentious topic, and owing to a lack of consensus, the WIP
recommendations on regridding remain in flux. The
\href{https://goo.gl/wVtm5t}{CMIP6 Output Grid Guidance document}
outlines a number of possible recommendations, including the provision
of ``weights'' to a target grid. Many of the considerations around
regridding, particularly for ocean data in CMIP6, are discussed at
length in \bibref{griffiesetal2016}. A similar lack of consensus has
made the WIP drop a recommendation of a common \emph{calendar} for
particular experiments: a wide variety of calendars are in use --
Gregorian, Julian, 365-day, and equal-month (360-day) all remain
popular options -- and the onus of converting data across the
multi-model ensemble (MME) to a common one for analysis remains upon
the end-user.

As outlined below in \secref{replica}, both ESGF data nodes and the
creators of secondary repositories are given considerable leeway in
choosing data subsets for replication, based on their own interests.
The tracking mechanisms outlined in \secref{pid} below will allow us
to ascertain, after the fact, how widely used the native grid data may
% "regridded subset" is referred to below for the first time.  The reader
% won't know what this is about without further explanation.
be \emph{vis-\`a-vis} the regridded subset, and allow us to
recalibrate the replicas, as usage data becomes available. We note
also that the providers of at least one of the standard metrics
packages \citep[ESMValTool,][]{ref:eyringetal2016a} have expressed a
preference of standard grid data for their analysis, as regridding
from disparate grids increases the complexity of their already
overburdened infrastructure.

\subsection{CMIP6 data volumes}
\label{sec:dvol}

As noted, extrapolations based on CMIP3 and CMIP5 lead to some
alarming trends in data volume \citep[see
e.g.,][]{ref:overpecketal2011}. The WIP has undertaken a rigorous
approach to the estimation of future data volumes, rather than simple
extrapolation. Contributions to increase in data volume include the
systematic increase in model resolution and complexity of the
experimental protocol and data request. We consider these separately:

\begin{description}
\item[Resolution] The median horizontal resolution of a CMIP model
  tends to grow with time, and is expected to be more typically 100~km
  in CMIP6, compared to 200~km in CMIP5. The vertical resolution grows
  in a more controlled fashion, at least as far as the data is
  concerned, as often the requested output is reported on a standard
  set of atmospheric levels that has not changed much over the years.
  Similarly the temporal resolution of the data request does not
  increase at the same rate as the model timestep: monthly averages
  remain monthly averages. A doubling of model resolution leads
  therefore to a quadrupling of the data volume, in principle. But
  typically the temporal resolution of the model (though not the data)
  is doubled as well, for reasons of numerical stability. Thus, for an
  $N$-fold increase in horizontal resolution, we require an $N^3$
  increase in computational capacity, which will result in an $N^2$
  increase in data volume. We argue therefore, that data volume $V$
  and computational capacity $C$ are related as $V \sim C^\frac23$,
  purely from the point of view of resolution. The exponent is even
  smaller if vertical resolution increases are assumed. If we then
  assume that centers will experience an 8-fold increase in $C$
  between CMIPs (which is optimistic in an era of tight budgets), we
  can expect a 4-fold increase in data volume. However, this is not
  what we experienced between CMIP3 and CMIP5. What caused that
  extraordinary 50-fold increase in data volume?
\item[Complexity] The answer lies in the complexity of CMIP: the
  complexity of the data request, and of the experimental protocol.
  The data request complexity is related to that of the science: the
  number of processes being studied, and the physical variables
  required for the study. In CPMIP \pipref{balajietal2017}, we have
  attempted a rigorous definition of this complexity, measured
  by the number of physical variables simulated by the model. This, we
  argue, grows not smoothly like resolution, but in very distinct
  generational step transitions, such as the one from
  atmosphere-ocean models to Earth system models, which involved a
  substantial jump in complexity, the number of physical, chemical,
  and biological species being modeled, as shown in
  \bibref{balajietal2017}.

  % the following increase in complexity doesn't help explain the 50-fold increase 
  % which is what this paragraph is supposed to address
  %  the number of experiments (or number of years simulated) are
  % primarily controlled by $C$, which you say is limited to 8-fold increase.
  %  need to restructure the argument.
  The second component of complexity is the experimental protocol, and 
  the number of experiments themselves when comparing CMIP5 and CMIP6.
  With the new structure of CMIP6, with a DECK and 21 endorsed MIPs,
  this would appear to have grown tremendously. We propose as a
  measure of experimental complexity, the \emph{total number of 
  simulated years (SYs)} conforming to a given protocol. Note that
  this too is gated by $C$: modeling centers usually make tradeoffs
  between experimental complexity and resolution in deciding their
  level of participation in CMIP6, discussed in 
  \bibref{balajietal2017}.
\end{description}

The WIP has recommended two further steps toward ensuring sustainable
growth in data volumes.
% Given the earlier arguments, it seems $C$ will limit growth of volume by itself
%  Why are additional steps necessary?

\begin{enumerate}
\item The first of these is the consideration of standard horizontal
  resolutions for saving data, as is already done for vertical and
  temporal resolution in the data request. Cross-model analyses
  already cast all data to a common grid in order to evaluate it as an
  ensemble, typically at fairly low resolution. The studies of Knutti
  and colleagues (e.g., \bibref{knuttietal2017}) are typically
  performed on relatively coarse grids. We recommend that for most
  purposes atmospheric data on the ERA-40 grid
  ($2^\circ\times 2.5^\circ$) would suffice, with of course exceptions
  % could reference in line below https://doi.org/10.5194/gmd-9-4185-2016
  for experiments like those called for by HighResMIP
  \pipref{haarsmaetal2016}. A similar recommendation is made for ocean
  data (the World Ocean Atlas $1^\circ\times 1^\circ$ grid), with
  extended discussion of the benefits and losses due to regridding
  \citep[see][]{ref:griffiesetal2014,ref:griffiesetal2016}.
\item The second is the issue of data compression. netCDF4, which is
  the WIP's required standard for CMIP6 data, includes an option
  for lossless compression or deflation \pipref{zivlempel1977} that
  relies on the same technique used in standard tools such
  as \texttt{gzip}. In practice, the reduction in data volume will
  depend upon the ``entropy'' or randomness in the data, with
  smoother data being compressed more.

  Deflation entails computational costs, not only during creation of
  the compressed data, but also every time the data are re-inflated.
  There is also a subtle interplay with precision: for instance
  temperatures usually seen in climate models appear to deflate better
  when expressed in Kelvin, rather than Celsius, but that is due to
  the fact that the leading order bits are always the same, and thus
  the data is actually less precise. Deflation is also enhanced by
  reorganizing (``shuffling'') the data internally into chunks that
  have spatial and temporal coherence.

  Some in the community argue for the use of more aggressive
  \emph{lossy} compression methods \pipref{bakeretal2016}, but the
  WIP, after consideration, believes the loss of precision entailed by
  such methods, and the consequences for scientific results, require
  considerably more evaluation by the community before such methods
  can be accepted as common practice.

  Given the options above, we undertook a systematic study of the
  behavior of typical model output files under lossless compression,
  the results of which are \href{https://goo.gl/qkdDnn}{publicly
    available}. The study indicates that standard \texttt{zlib}
  compression in the netCDF4 library with the settings of
  \texttt{deflate=2} (relatively modest, and computationally
  inexpensive), and \texttt{shuffle} (which ensures better
  spatiotemporal homogeneity) ensures the best compromise between
  increased computational cost and reduced data volume. For a coupled
  model, we expect a total savings of about 50\%, with ocean, ice,
  land realms getting the most savings (owing to large areas of the
  globe that are masked), and atmospheric data the least. This 50\%
  estimate has been verified with sample output from some models
  preparing for CMIP6.
\end{enumerate}

The \href{https://goo.gl/iNBQ9m}{DREQ} alluded to above in
\secref{dreq} allows us to make a systematic assessment of these
considerations. The tool expects one to input a model's resolution
along with the experiments that will be performed and the data one
intends to save (using DREQ's \emph{priority} attribute). With this
information
% We are actually capturing this information in the registered content
% for the model source_id entries - see http://rawgit.com/WCRP-CMIP/CMIP6_CVs/master/src/CMIP6_source_id.html
% The json entry contains resolutions for each active model realm
% https://github.com/WCRP-CMIP/CMIP6_CVs/blob/master/CMIP6_source_id.json
%  "unprecedented" is incorrect.
% In CMIP5 we had a sophisticated capability of estimating data volume
%  We polled the groups to determine which experiments they planned
% to run and how large their ensembles would be.  
%  We also asked what resolution they would report output.
%  From this we estimated in Nov. 2010 a total data volume of 2.5 petabytes 
%  (2.1 petabytes if only high-priority variables were reported), not too 
% far from the actual volume.  I'll send you the analysis if you like.
% The modeling groups had access to this information.
\href{https://goo.gl/Ezz5v3}{dreqDataVol.py}, which is a tool 
built atop DREQ available from the WIP website calculates the
data volume that will be produced. While similar
analyses were undertaken at PCMDI for CMIP5, this tool puts this
capability in the hands of the modeling centers themselves.

To make a preliminary estimate of total data volume, the WIP carried
out a survey of modeling centers in 2016, asking them for their
expected model resolutions, and intentions of participating in various
experiments. Based on that survey, we initially have forecast a data
volume of 18~PB for CMIP6. This assumes an overall 50\% compression
rate, which has been approximately verified for at least one CMIP6
model, and whose compression rates should be quite typical. This
number, 18~PB, is about 6 times the CMIP archive size, and can be
explained in terms of the compounding of modest increases in
resolution and complexity, as explained above. The more dramatic
increase in data volume between CMIP3 and CMIP5 was also due to these
same causes, but with a much larger change. Many models of the CMIP5
era added atmospheric chemistry and aerosol-cloud feedbacks, sometimes
with $\mathcal{O}(100)$ species. CMIP5 also marked the first time in
CMIP that ESMs were used to simulate changes in the carbon cycle and
modeling groups performed many more simulations than in CMIP3 with a
corresponding increase in years simulated. There is no comparable jump
between CMIP5 and CMIP6. CMIP6's innovative DECK/endorsed-MIP
structure should thus be seen as an extension and an attempt to impose
a rational order on CMIP5, rather than a qualitative leap.

% if you want to discuss different grids, perhaps here is a better place for
% that.
It should be noted that reporting output on a lower
resolution standard grid (rather than the native model grid) could
shrink this volume 10-fold, to 1.8~PB. This is an important number, as
will be seen below in \secref{replica}: the managers of Tier~1 nodes
have indicated that 2~PB is about the practical limit for replicated
storage of combined data from all models. The WIP believes
% I for one don't think it is important for all the data to be replicated
this target is achievable based on compression and the use of standard
grids. Both of these (the use of netCDF4 compression and regridding)
remain merely recommendations, and the centers are free to choose
whether or not to compress and regrid.

\section{Licensing}
\label{sec:licensing}

The WIP's recommended licensing policy is based on an examination of
data usage patterns in CMIP5. First, while the licensing policy called
for registration and acceptance of terms of use, a large fraction,
% https://pcmdi.llnl.gov/CMIP6/TermsOfUse is live - if you want to ref it
perhaps a majority of users, actually obtained their data not directly
from ESGF, but from other copies, such as the ``snapshots'' alluded to
above in Item~\ref{snap}, \secref{principles}. 
% I don't think there is any hard evidence that most users got data 
% from other than ESG, so I've changed "typical" to "common".
Those users accessing the data indirectly, as shown in \figref{dark},
relied on user groups or their home institutions to make secondary
repositories that could be more conveniently accessed. The WIP
\href{https://goo.gl/7vHsPU}{CMIP6 Licensing and Access Control}
position paper refers to the secondary repositories as ``dark'' and
those obtaining CMIP data from those reposistories as ``dark users''
who are invisible to the ESGF system. While this appears to subvert
the licensing and registration policy put in place for CMIP5, this
should not be seen as a ``bootleg'' process: it is in fact the most
efficient use of limited network bandwidth at the user sites. However,
this also removes the ability for users of these ``dark'' repositories
to benefit from the augmented provenance provided by infrastructure
updates, such as being notified of data retractions or replacements in
the case that contributed datasets are found to be erroneous and
replaced.

\begin{figure*}
  \begin{center}
    \includegraphics[width=175mm]{images/WIP-data-process.png}
  \end{center}
  \caption{Typical data usage pattern in CMIP5 involved users making
    local copies, and user groups making institutional-scale caches
    from ESGF. Figure courtesy Stephan Kindermann, DKRZ, adapted from
    WIP Licensing White Paper.}
  \label{fig:dark}
\end{figure*}

The WIP therefore recommends a licensing policy that inverts this and
removes the impossible task of license enforcement from the distribution 
system, and embraces the ``dark'' repositories and users.
To quote the WIP position paper:

\begin{quote}
  The proposal is that (1) a data license be embedded in the data
  files, making it impossible for users to avoid having a copy of the
  license, and (2) the onus on defending the provisions of the license
  be on the original modeling center...
\end{quote}

The data archive snapshots and emerging resources that combine
archival and analysis capabilities (e.g., NCAR's
\href{https://goo.gl/sYTxC2}{CMIP Analysis Platform}) will host data
and offload some of the network provisioning requirements from ESGF
nodes themselves.

Modeling centers are offered two choices of \emph{Creative Commons}
licenses: data covered by the \href{https://goo.gl/CY5m2v}{Creative
  Commons Attribution ``Share Alike'' 4.0 International License} will
be freely available; for centers with more restrictive policies, the
\href{https://goo.gl/KUNUKq}{Creative Commons Attribution
  ``NonCommercial Share Alike'' 4.0 International License}, which
restricts the data to non-commercial use. Further sharing of the data
is allowed, as the license travels with the data. The PCMDI website
provides a link to the current
\href{https://pcmdi.llnl.gov/CMIP6/TermsOfUse}{CMIP6 Terms of Use
  webpage}.

\section{Citation}
\label{sec:cite}

As noted above in \secref{principles}, the WIP's position on citation
flows from two underlying considerations: one, to provide proper
credit and formal acknowledgment of dataset authors; and the other, to
enable rigorous tracking of data provenance and data usage in
scholarly literature. The tracking itself serves the purpose of
facilitating scientific reproducibility and traceability, as well as
documenting the utility of datasets.

These principles outlined above also are well-aligned with the
\href{https://goo.gl/Pzb7F6}{Joint Declaration of Data Citation
  Principles} formulated by the Force11 (The Future of Research
Communications and e-Scholarship) Consortium. These amount to an
acknowledgment of the rapid evolution of digital scholarship and
archival, and updating the rules of scholarly publication for the
digital age. We must now recognize data itself, not just the
peer-reviewed literature, as a first-class output of the research
enterprise, and to be curated with the same care as a journal article,
if not more. Most journals and academies also now insist that data
used in the literature be made publicly available for independent
inquiry and reproduction of results. New services like
\href{http://www.scholix.org}{Scholix} are evolving to support the
exchange and access of such data-data and data-literature
interlinking.

Given the complexity of the CMIP6 data request, we expect a total
dataset count of $\mathcal{O}(10^6)$, as shown above in \secref{dvol}.
The WIP therefore recommends an approach to citation that addresses both
formally giving credit to data authors and providing authors with a means
to exactly reference the data they used. While the former mechanism fully
qualifies for citation by ensuring that adequate citation metadata are
available and data are long-term archived, the data referencing mechanism
does not offer such full citation capabilities, but instead is able to 
refer at a much finer level of granularity to the exact data used.

The recommendations, detailed in the
\href{https://goo.gl/BFn9Hq}{CMIP6 Data Citation and Long Term
  Archival} position paper, recognize two phases to the process: an
initial phase, when the data have been released and preliminary
community analysis is still underway (``Citation of Dynamic Data''),
and a second stage, when most errors in the data have been identified
and corrected. At this point the data will be transferred to long-term
archival (LTA) and deemed appropriate for interdisciplinary use, such
as in policy studies (``Citation of Stable Data'').

In the following, two types of \emph{persistent identifiers} (PIDs) are
distinguished: DOIs, which come with additional policies (used for
long-term archived data only, mandatory citation metadata), and Handles,
which do not convey particular policies (and are therefore not citable).
Technically, both rely on the same system, the global Handle System. The
specific use and how they complement each other is described in the
following:

\begin{itemize}
\item The \emph{dynamic data referencing} infrastructure relies on
  unique Handles assigned at the level of an \emph{atomic dataset} (a
  complete timeseries of one variable from one experiment and one
  model). The infrastructure for creating and using Handles is
  described below in secref{pid}. New dataset versions (see
  \secref{version}, below), and datasets for the same variable from
  different models, or different experiments, will all receive unique
  Handles.

  The WIP strongly recommends that PIDs be used to document all the
  datasets used in any study. However, given that the datasets
  assigned Handles may evolve as errors are found and corrections
  made, the Handles cannot and should not meet the standards for
  long-term curation, quality, and accessibility and can not be
  considered first-class citable entities. Their application in CMIP6
  is to enable fine-granular data referencing unrestricted by formal
  citation policies, which cannot be done using DOIs alone.
  
\item The \emph{stable data citation} infrastructure requires some
  additional steps to meet formal requirements for citable data.
  First, we ensure that there has been sufficient community
  examination of the data to qualify as peer review of data quality,
  Second, there are further steps of quality control to ensure
  standards of documentation and completeness, described below in
  \secref{qa}.

  Once these criteria have been satisfied, a \emph{digital object
    identifier} (DOI) will be assigned (``minted'', in the DOI jargon)
  to a dataset. These will be assigned by
  \href{https://www.datacite.org/dois.html}{DataCite}, a DOI-minting
  organization that requires stringent adherence to metadata and
  documentation requirements. For CMIP6, the DDC at DKRZ in Hamburg
  has volunteered to provide the DataCite DOI service. The process is
  described in greater detail in
  \bibref{stockhauselautenschlager2017}.

  Given the formality of the process and to encourage their use in
  providing credit to modeling groups, a DOI is not assigned to data
  at the same granularity as a Handle. The WIP has recommended two
  aggregations suitable for DOI minting:

  \begin{itemize}
  \item \emph{model/MIP data}, an aggregation of data contributed to
    one MIP by a single model;
  \item \emph{experiment data}, the aggregation of all the data
    produced by a model performing an experiment (all realizations of
    a single CMIP6 experiment).
    % I'm worried that the following parenthetical statement will be
    % mis-interpreted as *all* the realizations performed for a single
    % experiment.  I think the DOI should be assigned to a single 
    % realization.
    % (a specific experiment in the CMIP6 experimental hierarchy).
  \end{itemize}
\end{itemize}

The recommendations, detailed in the
\href{https://goo.gl/BFn9Hq}{CMIP6 Data Citation and Long Term
  Archival} position paper, recognize two phases to the process: an
initial phase, when the data have been released and preliminary
community analysis is still underway (``Citation of Evolving Data''),
and a second stage, when most errors in the data have been identified
and corrected. At this point the data will be transferred to long-term
archival (LTA) of the IPCC Data Distribution Centre (IPCC DDC) and deemed appropriate for interdisciplinary use, such
as in policy studies (``Citation of Stable Data''). The time for the DDC snapshot is linked to the IPCC AR6 schedule.

\begin{itemize}
\item The \emph{evolving data citation} infrastructure relies on a repository collecting citation information from the data providers and the \href{https://www.datacite.org}{DataCite} data infrastructure to assign \emph{digital object identifier (DOIs)} assigned at the levels of a  model/MIP (data contribution from one institution with one model to one MIP) and an experiment (data contribution from one institution with one model to one experiment). DataCite is a leading global non-profit organisation that provides persistent identifiers (DOIs) for research data.

  The WIP strongly recommends that the data source is cited in any study. However, given that the referenced data may evolve as errors are found and corrections made, after long-term archival of the data in the DDC, the WIP recommends to cite the stable DDC data, which meets the standards for long-term curation and quality and can be considered first-class citable entities. 
\item The \emph{stable data citation} infrastructure requires some
  additional steps to meet formal requirements for citable data. First, we
  ensure that there has been sufficient community examination of the
  data to qualify as informal community peer review of data quality, second, there are
  further steps of including available information from ancillary metadata repositories to the documentation (ES-DOC, errata and citation) and steps of technical quality control to ensure overall data and metadata consistency and completeness, described below in \secref{qa}. Once these criteria have been satisfied, a DOI will be issued by the IPCC DDC hosted at DKRZ. These will be compliant with these stringent adherence to metadata and
  documentation requirements of the IPCC DDC. 
\end{itemize}

The data citation approach is described in greater detail in \bibref{stockhauselautenschlager2017}.

\subsection{The CMIP6 Handle services}
\label{sec:pid}

The CMIP6 Handle service infrastructure is described in the
\href{https://goo.gl/miUREw}{CMIP6 Persistent Identifiers
  Implementation Plan} position paper. There are two stages, which are
  both enabled through the use of the global Handle registry:

\begin{itemize}
\item generation of Handles at the level of individual files. Handles
are embedded in the CMIP6 file netcdf headers and registered as part of
the ESGF data distribution process.
\item generation and registration of Handles at a coarser granularity
  of an atomic dataset, aggregating all files associated with a single
  variable from a single model running a single experiment, referred to
  as an \emph{atomic dataset} in ESGF terminology.
\end{itemize}

The Handles assigned at these two levels of the PID hierarchy identify
static entities: new versions of files or datasets will trigger the
creation of new PIDs, as described in \secref{version}, below. In
contrast, the model and simulation granularities are covered by the DOI
mechanisms described above in \secref{cite}. These levels are dynamic
as far as the PID infrastructure is concerned: new elements can be
added to the aggregation without modifying the PID. For the model data
aggregation, for example, the same PID will indicate an evolving number
of simulations as new experiments are performed with the model. This
PID architecture is shown in \figref{pidarch}.

But since the entities referred to by DOIs are dynamic, citation
requires authors to indicate a version reference. While this fulfills
the requirement to give credit, exact referencing of all datasets used
is still not possible as the granularity is too coarse. Indicating all
datasets used would result in impractically huge lists. To remedy this
and close the gap, the PID services offer authors to request individual
Handles for entire \emph{data carts}. These are not citable, but make
the process of exact referencing much easier.


\begin{figure*}
  \begin{center}
    \includegraphics[width=175mm]{images/PID-architecture.png}
  \end{center}
  \caption{PID architecture, showing layers in the PID hierarchy. In
    the lower layers of the hierarchy, PIDs are static once generated,
    and new datasets generate new versions with new PIDs. Figure
    courtesy Tobias Weigel.}
  \label{fig:pidarch}
\end{figure*}

The PID infrastructure is central to the replication
(\secref{replica}) and versioning (\secref{version}) strategies. In
addition, the WIP strongly recommends the publication of
\emph{PIDlists} (a flat list of all PIDs referenced) as supplementary
material alongside peer-reviewed CMIP6 publications, as a mechanism of
tracking dataset use and provenance.

The document further describes methods for generating and registering
Handles within the system, using the asynchronous messaging system
RabbitMQ. This system, designed in collaboration with ESGF developers,
and shown in \figref{pidflow}, guarantees, for example, that PIDs have
been correctly generated in accordance with the guidelines regarding
versioning. This system is thus an extension of the
\texttt{tracking-id} used in CMIP5, but with more rigorous checking
and quality control to ensure that new PIDs are generated when data
are modified. The dataset and file Handles are also associated with
basic metadata, called PID Kernel information \pipref{zhouetal2018},
which facilitate basic provenance recording. Datasets and files point
to each other to bind the granularities together. In addition, dataset
kernel information refers to previous and later versions, errata
information and replicas, explained in more detail in the position
paper.

\begin{figure*}
  \begin{center}
    \includegraphics[width=175mm]{images/PID-workflow.png}
  \end{center}
  \caption{PID workflow, showing the generation and registry of PIDs,
    with checkpoints where compliance is assured. Figure courtesy
    Tobias Weigel.}
  \label{fig:pidflow}
\end{figure*}

\subsection{Quality Assurance}
\label{sec:qa}

The WIP's view of quality assurance (QA) is very broad and
encompasses the entire data lifecycle, as shown in \figref{qa}. At all
stages, we keep in mind the issues of scientific reproducibility and
provenance capture. Further, as noted in Item~\ref{broad} in
\secref{principles}, the QA procedures must expand the circle of trust
to communities outside the Earth system modeling community.

\begin{figure*}
  \begin{center}
    \includegraphics[width=175mm]{images/WIP-QA.png}
  \end{center}
  \caption{Schematic of the phases of quality assurance, with earlier
    stages in the hands of modeling centers (left), and more formal
    long-term data curation stages at right. Quality assurance is
    applied both to the data (D, above) as well as the metadata (M)
    describing the data. Figure courtesy Martina Stockhause, drawn
    from the WIP's Quality Assurance position paper.}
  \label{fig:qa}
\end{figure*}

QA covers ensuring the scientific content of the data, scientific
descriptions of the data, and consistent practices allowing reliable
use by different elements of the toolchain (\figref{qa}). The early
stages of QA are in the hands of the data producers: in fact the cycle
of model development and diagnosis is the most elemental QA of all!
The second aspect is ensuring that disseminated data all include
common metadata based on common CVs that ensure consistent treatment
of data from different groups and institutions. These requirements are
directly embedded in the ESGF publishing process and in tools such as
\href{https://cmor.llnl.gov/}{CMOR} (and its validation component,
\href{https://goo.gl/ApvMJx}{PrePARE}). These checks (the D1 and M1
phases of QA in \figref{qa}) ensure that the data conform to the CMIP6
Data Request, conform to all naming conventions and CVs, and follow
the DRS for storage access patterns. As noted above in \secref{dreq},
many modeling centers have chosen to embed these steps directly in
their own workflows to ensure conformance as the models are being run
and their output processed.

At this point, as noted in \figref{qa} control is ceded to the ESGF
system, where designated QA nodes perform further QA checks. A
critical new step is the assignment of PIDs (\secref{pid}, the D2
stage of \figref{pidflow}), which, contrary to prior practice, is more
controlled, as the PID is the essential label of datasets across the
data lifecycle.

Beyond this, further stages of QA are to be handled within the ESGF
systems following procedures outlined in the
\href{https://goo.gl/eEr8bS}{CMIP6 Quality Assurance} position paper.
As described in \secref{cite}, the data are still under scientific
scrutiny by analysts beyond the data producers in what can be thought
of as an ongoing period of community-wide scientific checks of the
data. During this period, modeling centers may correct errors and
provide new versions of datasets. In the final stage, the data pass
into long-term archival, described as the ``bibliometric'' phase in
\figref{qa}. Just
% LTA needs to be defined before using here.
prior to LTA, the system will verify minimum standards of
provenance documentation. This is described in the next section.

\subsection{Documentation of provenance}
\label{sec:doc}

As noted earlier in \secref{dreq}, for data to become a first-class
scientific resource, the methods of their production must be documented
to the fullest extent possible. In particular for CMIP6, this includes
documenting the models and experiments. While of course this is done
through the peer-reviewed literature, we note the need for structured
documentation in machine-readable form for various aspects of search,
discovery and tracking of datasets.

\begin{figure*}
  \begin{center}
    \includegraphics[width=120mm]{images/ES-DOC-process.png}
  \end{center}
  \caption{Flowchart of ES-DOC documentation process, delineating
    sequence of events and indicating the parties responsible for
    producing the documentation. Figure courtesy Eric Guilyardi and
    Mark Greenslade.}
  \label{fig:esdoc}
\end{figure*}

In CMIP6, the documentation of \emph{experiments}, \emph{models} and
\emph{simulations} is done through the Earth System Documentation
\citep[\href{https://goo.gl/WNwKD9}{ES-DOC},][]{ref:guilyardietal2013}
Project. The various aspects of model documentation are shown in
\figref{esdoc}, and in greater detail in the WIP position paper on
\href{https://goo.gl/S3vVxE}{ESDOC}. The CMIP6 experimental design has
been translated into structured text documents, already available from
ES-DOC. ES-DOC has constructed CVs for the description of the CMIP6
standard model realms, including a set of short tables
(\emph{specialisations}, in ES-DOC terminology) for each realm. The
WIP, and the CMIP Panel, have strongly recommended that the modeling
groups integrate their provision of documentation to ES-DOC with their
model development process and documentation through the normal
peer-reviewed literature. This will better ensure consistency. ES-DOC
provides a variety of user interfaces to read and write the structured
documentation which follows the Common Information Model (CIM) of
\bibref{lawrenceetal2012}. As models evolve or differentiate (for
example, an Earth system model derived from a particular general
circulation model), branches and new versions of the documentation can
be produced in a manner familiar to anyone who works with
version-controlled code.

A critical element in the ESDOC process is the documentation of
\emph{conformances}: steps undertaken by the modeling centers to
ensure that the simulation was conducted as called for by the
experiment design. It is here that we rigorously document which input
datasets were used in a simulation \citep[e.g., the version of each of
the forcing datasets, see][]{ref:duracketal2017}. The conformances
will be an important element in the construction of ensembles in the
CMIP6 archive. We may, for example, choose to subselect only those
models that used a particular version of the forcings. The
conformances will continue to grow in importance following the vision
of the DECK providing the continuing thread anchoring a series of
CMIPs \citep[viz. the well-known Figure~1 of][]{ref:eyringetal2016a}.
The conformances will be essential in studies across model
generations. The method of capturing the conformance documentation is
a two-stage process that has been designed to limit the amount of work
required by a modeling center. The first stage is to capture the many
conformances that will be common to all simulations, thereby removing
a lot of duplicated effort. ESDOC will then automatically copy these
common conformances to the correct simulations. This is followed by a
second stage in which those conformances that are specific to
individual experiments or simulations are collected.

While this method of documentation is unfamiliar to many in the
community, the WIP would like to emphasize its importance, in keeping
pace with evolving scientific publication practices in the digital
age. Documentation of software validation \citep[see
e.g][]{ref:peng2011} and structured documentation of complete
scientific workflows that can be independently read and processed, are
both becoming more common \citep[see the special issue on the
``Geoscience Paper of the Future'', ][]{ref:davidetal2016}. We have
noted earlier (see Item~\ref{repro} in \secref{principles}) the
special importance in climate research today of documenting how
results have been obtained and enabling results to be reproduced by
others. Rigorous documentation remains our best bulwark against
challenges to our results.

In keeping with the WIP's  ``dataset-centric rather than system-centric''
principle approach (Item~\ref{snap} in
\secref{principles}), a user will be linked to the documentation
directly from each dataset. This is done in CMIP6 by embedding a global
attribute \texttt{further\_info\_URL} in file headers pointing to the
associated Common Information Model (CIM) 
% Can CIM be expanded "Climate Information Model"?
document, which will serve as the landing page for
documentation from which further exploration (by humans or software)
will take place. The existence and functioning of the landing page is
assured in Stage~M3 of \figref{qa}.

\section{Replication}
\label{sec:replica}

The WIP's replication strategy is covered in the
\href{https://goo.gl/Bs4Qou}{CMIP6 Replication and Versioning}
position paper. The recommendations therein are based on the following
\emph{primary} goal:

\begin{itemize}
\item Ensuring at least one copy of a dataset is present at a stable
ESGF node with a mission of long-term maintenance and curation of
data. The total data storage resources planned across
  the Tier~1 nodes in the CMIP6 era is adequate to support this
  requirement, though some data will likely be held on accessible tape
  storage rather than spinning disk.
\end{itemize}

In addition, we have articulated a number of secondary goals:

\begin{itemize}
\item Enhancing data accessibility across the ESGF (e.g. Australian
  data easily accessible to the European continent despite the long
  distance);
\item Enabling each Tier 1 data node to enact specific policies to support their
  local objectives;
\item Ensuring that the most widely requested data is the most
  accessible across the ESGF federation;
\item Enabling large-scale data analysis across the federation (see
  Item~\ref{analysis} in \secref{principles});
\item Ensuring continuity of data access in the event of individual node
  failures;
\item Enabling network load-balancing and enhanced performance;
\item Reducing the manual workload related to replication;
\item Building a reliable replication mechanism that can be used not
  only within the federation, but by the secondary repositories
  created by user groups (see discussion in \secref{licensing} around
  \figref{dark}).
\end{itemize}

In conjunction with the ESGF and the International Climate Networking
Working Group (ICNWG), these recommendations have been translated to a
two-pronged strategy.

The basic toolchain for replication is built on updated versions of the 
software layers used in CMIP5 including:
% I'm not sure I understand what's being said in the following.  Please check!
\href{https://github.com/Prodiguer/synda}{synda} (formerly
\texttt{synchrodata}) and Globus Online \pipref{chardetal2015}, which
are based on underlying data transport mechanisms such as
\href{https://goo.gl/Z8xcfE}{gridftp} and the older and now deprecated
protocols like \texttt{wget} and \texttt{ftp}.

As before, these layers can be used for \emph{ad hoc} replication by
sites or user groups. For \emph{ad hoc} replication, there is no
obvious mechanism for triggering updates or replication when new data
are published (or retracted, see \secref{version} below). Therefore,
the WIP recommends that designated \emph{replica nodes} maintain a
protocol for automatic replication, shown in \figref{replica}.

\begin{figure*}
  \begin{center}
    \includegraphics[width=120mm]{images/WIP-replication.png}
  \end{center}
  \caption{CMIP6 replication from data nodes to replica centers and
    between replica centers coordinated by a CMIP6 replication team.}
  \label{fig:replica}
\end{figure*}

Given the nature of some of the secondary goals listed above, it would
not be appropriate for the WIP to prescribe which data should be
replicated by each center. Rather, the plan should be flexible to
accommodate changing data use profiles and resource availability. The
WIP consider the CDNOT group to be the appropriate organisation to
coordinate the replication activities of the CMIP6 data nodes such
that the primary goal is achieved and an effective compromise for the
secondary goals is established.

The
International Climate Network Working Group (ICNWG), formed under the
Earth System Grid Federation (ESGF), helps set up and optimize network
infrastructures for ESGF climate data sites located around the world.
For example prioritising the most widely requested data for
replication can best be done based on operational experience and will
of course change over time. To ensure that the replication strategy is
responding to user need and data node capabilities, the replication
team will maintain and run a set of monitoring and notification tools
assuring that replicas are up-to-date. The CDNOT is tasked with
ensuring the deployment and smooth functioning of replica nodes.

A key issue that emerged from discussions with node managers is that
the replication target has to be of sustainable size. The WIP has
concluded from the discussions that a replication target about 2~PB in
size is the practical (technical and financial) limit for CMIP6 online
(disk) storage at any single location. Replication beyond this may
involve offline storage (tape) for disaster recovery.

Based on experience in CMIP5, it is expected that a number of
``special interest'' secondary repositories will hold selected subsets
of CMIP6 data outside of the ESGF federation. This will have the
effect of widening data accessibility geographically, and by user
communities, with obvious benefit to the CMIP6 program. The WIP
encourages the support of these secondary repositories where it
does not undermine CMIP6 data management and integrity objectives.

In CMIP5 a significant issue for users of some third-party archives
was that their replicated data was taken as a one-time snapshot (see
discussion above in Item~\ref{snap} in \secref{principles}), and not
updated as new versions of the data were submitted to the source ESGF
node. Tools have been developed by a number of organisations to
maintain locally synchronized archives of CMIP5 data and third party
providers should be encouraged to make use of these types of tools to
keep the local archives up to date.

In summary, the WIP requirements for replication are limited to
ensuring:

\begin{itemize}
\item that there is at least one instance of each submitted dataset
  stored at a Tier~1 node (in addition to its primary residence)
  within a reasonably short time period following submission;
\item that subsequent versions of submitted datasets are also
  replicated by at least one Tier~1 node (see versioning discussion
  below in \secref{version});
\item that creators of secondary repositories take advantage of the
  replication toolchain described here, to maintain replicas that can
  be kept up to date, rather than one-time snapshots
\item that the CDNOT is the recognized body to manage the operational
  replication strategy for CMIP6.
\end{itemize}

\section{Versioning}
\label{sec:version}

The WIP position on versioning is based on the principle
(\secref{principles}) of scientific reproducibility. Recognizing that
errors may be found after datasets have been distributed, the WIP
insists that erroneous datasets that may have been used downstream
continue to be publicly available, but marked as superseded. This will
allow users to trace the provenance of published results, even if
those point to retracted data; and further allow the possibility of
\emph{a~posteriori} correction of such results.

The WIP requires a consistent versioning methodology across all the
ESGF data nodes. We note that inconsistent or informal versioning
practices at individual nodes would likely be invisible to the ESGF
infrastructure (e.g., yielding files that look like replicas, but with
inconsistent data and checksums), which would inhibit traceability
across versions.

In close consultation with the ESGF implementation teams, the WIP has
made the following recommendations, described in greater depth in the
\href{https://goo.gl/Bs4Qou}{CMIP6 Replication and Versioning}
position paper:

\begin{itemize}
  % should specify *which* PID is referred to in the following.
\item the PID infrastructure of \secref{cite} is the basis of creating
  versions of datasets. PIDs are permanently associated with a
  dataset, and new versions will get a new PID. When new versions are
  published, there will be two-way links created within the PID kernel
  information so that one may query a PID for prior or subsequent
  versions.
\item we recommend the unit of versioning be an \emph{atomic dataset}:
  a complete timeseries of one variable from one experiment and one
  model. The implication is that other variables need not be
  republished, if the error is found in a single variable. If an entire
  experiment is retracted and republished, all variables will get a
  consistent version number.
\item the CDNOT will ensure consistent versioning practices at all
  participating data nodes.
\end{itemize}

\subsection{Errata}
\label{sec:errata}

% The following description of CMIP5 errata is not quite right and should
% be revised.
It is worth highlighting in particular the new recommendations
regarding errata. Until CMIP5, we have relied on the ESGF system to
push notifications to registered users regarding retractions and
reported errors. This was found to result in imperfect coverage: as
noted in \secref{licensing}, a substantial fraction of users are
invisible to the ESGF system. Therefore, following the discussion in
\secref{principles} (see Item~\ref{snap}), we have recommended a
design which is dataset-centric rather than system-centric.
Notifications are no longer pushed to users; rather they will be able
to query the status of a dataset they are working with. An
\emph{errata client} will allow the user to enter a PID to query its
status; and an \emph{errata server} will return the PIDs associated
with prior or posterior versions of that dataset, if any. Details are
to be found in the \href{https://goo.gl/fvVTVo}{Errata} position
paper.

\conclusions[The future of the global data infrastructure]
\label{sec:summary}

The WIP was formed in response to the explosive growth of CMIP between
CMIP3 and CMIP5, and charged with studying and making recommendations
about the global data infrastructure needed to support CMIP6 and the
future evolution of intercomparison projects. Our findings reflect 
the fact that CMIP is no longer a cottage industry, and a more formal 
approach is needed. The resulting recommendations stop well short of 
any sort of global governance of this ``vast machine'', but list many 
areas where, with a relatively light touch, beneficial order and 
control result. We emphasize here again some of the key aspects of 
the design:

\begin{itemize}
\item The design is now dataset-centric rather than system-centric:
  see for example the discussion of licensing (\secref{licensing}) and
  dataset tracking (\secref{pid}). This relieves a considerable design
  burden from the ESGF software stack, and further, recognizes that
  the data ecosystem extends well beyond the reach of any software
  system and that data will be used and reused in myriad ways outside
  anyone's control.
\item Standards, conventions, and vocabularies are now stored in
  machine-readable structured text formats like XML and JSON, thereby
  enabling software to automate aspects of the process. We believe
  this meets an existing urgent need, with some modeling centers
  already exploiting this structured information to mitigate against
  the overwhelming complexity of experimental protocols. Moreover, we
  believe this will also enable and encourage unanticipated future use
  of the information in developing new software tools for exploiting
  it as technologies evolve. Our ability to predict (whether correctly
  or not remains to be seen) the expected CMIP6 data volume is one
  such unexpected outcome.
\item The infrastructure allows user communities to assess the costs
  of participation as well as the benefits. For example, we believe
  the new PID-based methods of dataset tracking will allow centers to
  measure which data has value downstream. The importance of citations
  and fair credit for data providers is recognized, with a design that
  facilitates and encourages proper citation practices.
\end{itemize}

Certainly not all issues are resolved, and the validation of some of
our findings will have to await the outcome of CMIP6. Nevertheless, we
believe the discussion in this article provides a sound basis for
beginning to think about the future.

\begin{itemize}
\item There is an increasing blurring of the boundary between weather
  and climate as time and space scales merge \pipref{hoskins2013}.
  This will increasingly entrain new communities into our data
  ecosystems, each with their own modeling and analysis practices,
  standards and conventions, and other issues. The establishment of
  the WIP was a crucial step in enhancing the capabilities, standards,
  protocols and policies around the CMIP enterprise. Earlier
  discussions on the scope of the WIP also suggested a broader scope
  for the panel on the longer-term, to coordinate not only the CMIP
  data aspects (including for example, the CORDEX project
  \citep{ref:lakeetal2017}, which also relies upon ESGF for data
  dissemination, see \figref{esgf}) but also the climate prediction
  (seasonal to decadal) issues and corresponding observational and
  reanalysis aspects.We would recommend a closer engagement between
  these communities in planning the future of global data
  infrastructure.
\item As we have noted, the nature of publication is changing
  \citep[see e.g][]{ref:davidetal2016}. In the future, datasets and
  software with provenance information will be first-class entities of
  scientific publication, alongside the traditional peer-reviewed
  article. In fact it is likely that those will increasingly feature
  % I don't understand what is being said in this next bit.  Can it
  % be reworded/clarified somehow?
  in the grey literature and scientific social media: one can imagine
  blog posts and direct annotations on the published literature using
  analysis directly performed on datasets using their PIDs. Data
  analytics at large scale is increasingly moving toward machine
  learning and other directly data-driven methods of analysis, which
  will also be dependent on data with provenance tracking. We believe
  our community needs to pay increasing heed to the status of their
  data and software.
\end{itemize}

% not sure we want to promise this.  We risk not being able to take
% care of the the MIPs properly if we expand.
The WIP is well-positioned to extend its activities as these
developments continue.

\appendix

\section{List of WIP position papers}
\label{sec:wip}


\begin{itemize}
\item \href{https://goo.gl/4A1Xtq}{CDNOT Terms of Reference}: a
  charter for the CMIP6 Data Node Operations Team. Authorship: WIP.
\item \href{https://goo.gl/mSe4rf}{CMIP6 Global Attributes, DRS,
    Filenames, Directory Structure, and CVs}: conventions and
  controlled vocabularies for consistent naming of files and
  variables. Authorship: Karl E. Taylor, Martin Juckes, V. Balaji,
  Luca Cinquini, Sébastien Denvil, Paul J. Durack, Mark Elkington,
  Eric Guilyardi, Slava Kharin, Michael Lautenschlager, Bryan
  Lawrence, Denis Nadeau, and Martina Stockhause, and the WIP.
\item \href{https://goo.gl/miUREw}{CMIP6 Persistent Identifiers
    Implementation Plan}: a system of identifying and citing datasets
  used in studies, at a fine grain. Authorship: Tobias Weigel, Michael
  Lautenschlager, Martin Juckes and the WIP.
\item \href{https://goo.gl/Bs4Qou}{CMIP6 Replication and Versioning}:
  a system for ensuring reliable and verifiable replication; tracking
  of dataset versions, retractions and errata. Authors: Stephan
  Kindermann, Sebastien Denvil and the WIP.
\item \href{https://goo.gl/eEr8bS}{CMIP6 Quality Assurance}: systems
  for ensuring data compliance with rules and conventions listed
  above. Authorship: Frank Toussaint, Martina Stockhause, Michael
  Lautenschlager and the WIP.
\item \href{https://goo.gl/BFn9Hq}{CMIP6 Data Citation and Long Term
    Archival}: a system for generating Document Object Identifies
  (DOIs) to ensure long-term data curation. Authorship: Martina
  Stockhause, Frank Toussaint, Michael Lautenschlager, Bryan Lawrence
  and the WIP.
\item \href{https://goo.gl/7vHsPU}{CMIP6 Licensing and Access
    Control}: terms of use and licenses to use data. Authorship: Bryan
  Lawrence and the WIP.
\item \href{https://goo.gl/jWfrWb}{CMIP6 ESGF Publication
    Requirements}: linking WIP specifications to the ESGF software
  stack, conventions that software developers can build against.
  Authorship: Martin Juckes and the WIP.
\item \href{https://goo.gl/fvVTVo}{Errata System for CMIP6}: a system
  for tracking and discovery of reported errata in the CMIP6 system.
  Authorship: Guillaume Levavasseur, Sébastien Denvil, Atef Ben
  Nasser, and the WIP.
\item \href{https://goo.gl/S3vVxE}{ESDOC Documentation}: An overview
  of the process for providing structured documentation of the models,
  experiments and simulations that produce the CMIP6 output datasets,
  by the ES-DOC Team.
\end{itemize}

\section{Data and code availability}
\label{sec:code}

\begin{itemize}
\item The software and data used for the study of data compression are
  available at \url{https://goo.gl/qkdDnn}, courtesy Garrett Wright.
\item The software and data used for the prediction of data volumes
  are available at \url{https://goo.gl/Ezz5v3}, courtesy Nalanda
  Sharadjaya.
\end{itemize}

Most of the software referenced here for which the WIP is providing
design guidelines and requirements, but not implementation, including
the ESGF, ESDOC, DREQ software stacks are open source and freely
available. They are autonomous projects and therefore not listed here.

\begin{acknowledgements}
  We thank Michel Rixen, Stephen Griffies, and John Krasting for their
  close reading and comments on early drafts of this manuscript.
  Colleen McHugh aided with the analysis of data volumes.
  
  The research leading to these results has received funding from the
  European Union Seventh Framework program under the IS-ENES2 project
  (grant agreement No. 312979).

  V. Balaji is supported by the Cooperative Institute for Climate
  Science, Princeton University, Award NA08OAR4320752 from the
  National Oceanic and Atmospheric Administration, U.S. Department of
  Commerce. The statements, findings, conclusions, and recommendations
  are those of the authors and do not necessarily reflect the views of
  Princeton University, the National Oceanic and Atmospheric
  Administration, or the U.S. Department of Commerce.

  B.N. Lawrence acknowledges additional support from the UK Natural
  Environment Research Council.
  
  K.E. Taylor and P.J. Durack are supported by the Regional and Global
  Model Analysis Program of the United States Department of Energy's
  Office of Science, and their work was performed under the auspices
  of Lawrence Livermore National Laboratory's Contract
  DE-AC52-07NA27344.
\end{acknowledgements}

\bibliographystyle{copernicus}
\bibliography{refs}
\end{document}
